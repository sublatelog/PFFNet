tools/train_net.py
main()
    parser.add_argument()
    
    # local_rank:default=0
    # distributed:num_gpus > 1
    train(cfg, args.local_rank, args.distributed)
        model = build_detection_model(cfg)
            GeneralizedRCNN(cfg)
                # R-101-FPN
                backbone, semseg = build_backbone(cfg)
                    body = resnet.ResNet(cfg)
                    
                    # ResNet_fpn
                    fpn = fpn_module.FPN(...)
                    model = nn.Sequential(OrderedDict([("body", body), ("fpn", fpn)])) # OrderedDict:順序付き辞書
                    
                    # ResNet_semantic
                    sem_branch = mcgcn.RGCN(in_channels_list, middle_channels, sem_out_channel, conv_block) # PFFNet/maskrcnn_benchmark/modeling/sem_branch/mcgcn.py
                        RGCN(nn.Module):
                            for idx, in_channels in enumerate(in_channels_list, 1):
                                gcn_block  = RESBlock[x_conv_conv_out+res]
                                res_block  = GCNBlock[conv5_1_conv1_5+conv1_5_conv5_1]
                                res2_block = GCNBlock[conv5_1_conv1_5+conv1_5_conv5_1]
                                inner_block = conv1_1
                                layer_block = conv3_3
                            
                            # last_inner
                            last_inner = gcn_block__res2_block
                            
                            for idx, in_channels in enumerate(in_channels_list, 1):
                                # scaled_last_inner
                                inner_top_down = F.interpolate(last_inner, scale_factor=2, mode="nearest")
                                
                                # this_inner_lateral2
                                inner_lateral2 = gcn_blocks__res2_blocks

                                # last_inner
                                last_inner_pre = inner_lateral2 + inner_top_down
                                last_inner = res_blocks[-idx+1])(last_inner_pre)
                                
                                results.insert(0, last_inner)
                            
                            
                    model_sem = nn.Sequential(OrderedDict([("body", body), ("semseg", sem_branch)]))
                    
                
                rpn = build_rpn(cfg, self.backbone.out_channels)
                roi_heads = build_roi_heads(cfg, self.backbone.out_channels)
                roi_feature_fusion = build_roi_feature_fusion(cfg)
        
        optimizer = make_optimizer(cfg, model)
        scheduler = make_lr_scheduler(cfg, optimizer)
        
        # FP16の演算を前提とした(順および逆)伝播計算等を支援する関数
        model, optimizer = amp.initialize(model, optimizer, opt_level=amp_opt_level)
        
        checkpointer = DetectronCheckpointer(cfg, model, optimizer, scheduler, output_dir, save_to_disk)
        
        data_loader = make_data_loader(cfg, is_train=True, is_distributed=distributed, start_iter=arguments["iteration"],)
        data_loader_val = make_data_loader(cfg, is_train=False, is_distributed=distributed, is_for_period=True)
        
        do_train(cfg, model, data_loader, data_loader_val, optimizer, scheduler, checkpointer, device, checkpoint_period, test_period, arguments, )
            # GeneralizedRCNN
            model.forward(self, images, targets=None, semgt = None)
                features_all = self.backbone(images.tensors)
                
                # feature
                features = features_all[1:]
                
                # semantic
                fpn_semantic_pred = features_all[0]
                pred_sembranch = self.semseg(images.tensors)
                
                # rpn
                proposals, proposal_losses, feat_rpn_scales = self.rpn(images, features, targets)
                
                # roi
                x, result, detector_losses, masks, bboxes = self.roi_heads(features, proposals, targets)
                
                # loss detector, proposal
                losses = {}
                losses.update(detector_losses)
                losses.update(proposal_losses)
                
                # loss semantic
                sembranch_loss = nn.CrossEntropyLoss()(pred_sembranch, gt_semseg)
                sembranch_losses = {'loss_sem_branch': sembranch_loss}
                losses.update(sembranch_losses)
                
                # loss mask
                pred_maskfusion = self.roi_feature_fusion(masks, bboxes, fpn_semantic_pred)
                maskfusion_loss = nn.CrossEntropyLoss()(pred_maskfusion, gt_semseg)
                maskfusion_losses = {'loss_mask_fusion': maskfusion_loss}
                losses.update(maskfusion_losses)
                
                # loss semantic_mask
                prob_sembranch = nn.Softmax(dim=1)(pred_sembranch)
                prob_maskfusion = nn.Softmax(dim=1)(pred_maskfusion)
                sem_consistence_loss = nn.MSELoss()(prob_sembranch, prob_maskfusion) * self.sem_consistence_lambda
                sem_consistence_losses = {'loss_sem_consistence': sem_consistence_loss}
                losses.update(sem_consistence_losses)
                
                return losses
                













------------------------------------------------------------------------------------------------------------------------------------------------
configs/biomed_seg/e2e_mask_rcnn_R_101_FPN_1x_gn-tnbc.yaml

MODEL:
  META_ARCHITECTURE: "GeneralizedRCNN"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101-GN"
  BACKBONE:
    CONV_BODY: "R-101-FPN"
  RESNETS: # use GN for backbone
    BACKBONE_OUT_CHANNELS: 256
    STRIDE_IN_1X1: False
    TRANS_FUNC: "BottleneckWithGN"
    STEM_FUNC: "StemWithGN"
  FPN:
    USE_GN: True # use GN for FPN
  RPN:
    USE_FPN: True
    ANCHOR_STRIDE: (4, 8, 16, 32, 64)
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    PRE_NMS_TOP_N_TRAIN: 1000
    POST_NMS_TOP_N_TRAIN: 500
    PRE_NMS_TOP_N_TEST: 4000
    POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TEST: 1000
  ROI_HEADS:
    USE_FPN: True
    BATCH_SIZE_PER_IMAGE: 256
    POSITIVE_FRACTION: 0.25
    NMS: 0.3
    DETECTIONS_PER_IMG: 500
  ROI_BOX_HEAD:
    USE_GN: True # use GN for bbox head
    POOLER_RESOLUTION: 7
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    POOLER_SAMPLING_RATIO: 2
    FEATURE_EXTRACTOR: "FPN2MLPFeatureExtractor"
    PREDICTOR: "FPNPredictor"
    NUM_CLASSES: 2
  ROI_MASK_HEAD:
    USE_GN: True # use GN for mask head
    POOLER_SCALES: (0.25, 0.125, 0.0625, 0.03125)
    CONV_LAYERS: (256, 256, 256, 256)
    FEATURE_EXTRACTOR: "MaskRCNNFPNFeatureExtractor"
    PREDICTOR: "MaskRCNNC4Predictor"
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 2
    RESOLUTION: 28
    SHARE_BOX_FEATURE_EXTRACTOR: False
    DUAL_MODAL: True
  MASK_ON: True
  MASKIOU_ON: True
  PANOPTIC:
    PS_ON: True
    SEM_PATH: "./datasets/cell-tnbc/semgt"
    ATTENTION_FUSION: True
    SEMANTIC_CONSISTENCE: True
    SEMANTIC_CONSISTENCE_LAMBDA: 1.0
DATASETS:
  TRAIN: ("cell_tnbc",)
  TEST: ("cell_tnbc",)
DATALOADER:
  SIZE_DIVISIBILITY: 32
SOLVER:
  # Assume 8 gpus
  BASE_LR: 0.003
  WEIGHT_DECAY: 0.0001
  STEPS: (9000, 12000)
  MAX_ITER: 12000
  IMS_PER_BATCH: 1
  EPOCH_PERIOD: 1500
  CHECKPOINT_PERIOD: 100000
TEST:
  IMS_PER_BATCH: 1
INPUT:
  MAX_SIZE_TRAIN: 256
  MAX_SIZE_TEST: 512
  PIXEL_MEAN: [128.0, 128.0, 128.0] # coco default: [102.9801, 115.9465, 122.7717]
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  VERTICAL_FLIP_PROB_TRAIN: 0.5
